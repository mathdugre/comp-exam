
@article{4610935,
  author  = {IEEE},
  journal = {IEEE Std 754-2008},
  title   = {{IEEE Standard for Floating-Point Arithmetic}},
  year    = {2008},
  volume  = {},
  number  = {},
  pages   = {1-70},
  doi     = {10.1109/IEEESTD.2008.4610935}
}

@article{Abraham2014-zv,
  title    = {{Machine learning for neuroimaging with scikit-learn}},
  author   = {Abraham, Alexandre and Pedregosa, Fabian and Eickenberg, Michael
              and Gervais, Philippe and Mueller, Andreas and Kossaifi, Jean and
              Gramfort, Alexandre and Thirion, Bertrand and Varoquaux, Ga{\"e}l},
  abstract = {Statistical machine learning methods are increasingly used for
              neuroimaging data analysis. Their main virtue is their ability to
              model high-dimensional datasets, e.g., multivariate analysis of
              activation images or resting-state time series. Supervised
              learning is typically used in decoding or encoding settings to
              relate brain images to behavioral or clinical observations, while
              unsupervised learning can uncover hidden structures in sets of
              images (e.g., resting state functional MRI) or find
              sub-populations in large cohorts. By considering different
              functional neuroimaging applications, we illustrate how
              scikit-learn, a Python machine learning library, can be used to
              perform some key analysis steps. Scikit-learn contains a very
              large set of statistical learning algorithms, both supervised and
              unsupervised, and its application to neuroimaging data provides a
              versatile tool to study the brain.},
  journal  = {Front. Neuroinform.},
  volume   = 8,
  pages    = {14},
  month    = feb,
  year     = 2014,
  keywords = {Python; machine learning; neuroimaging; scikit-learn; statistical
              learning},
  language = {en},
  issn     = {1662-5196},
  pmid     = {24600388},
  doi      = {10.3389/fninf.2014.00014}
}

@inproceedings{Anderson2016-yn,
  title     = {{Vectorization of multibyte floating point data formats}},
  booktitle = {{2016 International Conference on Parallel Architecture and
               Compilation Techniques (PACT)}},
  author    = {Anderson, Andrew and Gregg, David},
  abstract  = {We propose a scheme for reduced-precision representation of
               floating point data on a continuum between IEEE-754 floating
               point types. Our scheme enables the use of lower precision
               formats for a reduction in storage space requirements and data
               transfer volume. We describe how our scheme can be accelerated
               using existing hardware vector units on a general-purpose
               processor (GPP). Exploiting native vector hardware allows us to
               support reduced precision floating point with low overhead. We
               demonstrate that supporting reduced precision in the compiler as
               opposed to using a library approach can yield a low overhead
               solution for GPPs.},
  pages     = {363--372},
  month     = sep,
  year      = 2016,
  keywords  = {Hardware;Standards;Writing;Software;Approximation
               algorithms;Memory management;Approximate Computing;Floating
               Point;Multiple Precision;SIMD;Vector Architecture},
  doi       = {10.1145/2967938.2967966}
}

@misc{bfloat16,
  title        = {{BFloat16: The secret to high performance on Cloud TPUs}},
  url          = {https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus},
  howpublished = {\url{https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus}},
  journal      = {Google},
  publisher    = {Google},
  author       = {Google},
  year         = {2019},
  month        = {August}
}

@misc{bfloat16-png,
  title        = {{bfloat16 representation compared to IEEE binary16 and binary32}},
  url          = {https://cloud.google.com/tpu/docs/images/bfloat16.png},
  howpublished = {\url{https://cloud.google.com/tpu/docs/images/bfloat16.png}},
  author       = {Google},
  year         = {2022},
  note         = {Accessed: 2022-05-26}
}

@article{Brunn2021-zj,
  title    = {{Fast GPU 3D diffeomorphic image registration}},
  author   = {Brunn, Malte and Himthani, Naveen and Biros, George and Mehl,
              Miriam and Mang, Andreas},
  abstract = {3D image registration is one of the most fundamental and
              computationally expensive operations in medical image analysis.
              Here, we present a mixed-precision, Gauss-Newton-Krylov solver
              for diffeomorphic registration of two images. Our work extends
              the publicly available CLAIRE library to GPU architectures.
              Despite the importance of image registration, only a few
              implementations of large deformation diffeomorphic registration
              packages support GPUs. Our contributions are new algorithms to
              significantly reduce the run time of the two main computational
              kernels in CLAIRE: calculation of derivatives and scattered-data
              interpolation. We deploy (i) highly-optimized, mixed-precision
              GPU-kernels for the evaluation of scattered-data interpolation,
              (ii) replace Fast-Fourier-Transform (FFT)-based first-order
              derivatives with optimized 8th-order finite differences, and
              (iii) compare with state-of-the-art CPU and GPU implementations.
              As a highlight, we demonstrate that we can register 2563 clinical
              images in less than 6 seconds on a single NVIDIA Tesla V100. This
              amounts to over 20$\times$ speed-up over the current version of
              CLAIRE and over 30$\times$ speed-up over existing GPU
              implementations.},
  journal  = {J. Parallel Distrib. Comput.},
  volume   = 149,
  pages    = {149--162},
  month    = mar,
  year     = 2021,
  keywords = {Diffeomorphic Image Registration; GPU computing;
              Gauss--Newton--Krylov Method; Mixed-Precision Solver; Parallel
              Optimization},
  language = {en},
  issn     = {0743-7315},
  pmid     = {33380769},
  doi      = {10.1016/j.jpdc.2020.11.006},
  pmc      = {PMC7769216}
}

@inproceedings{Carmichael2019-nu,
  title     = {{Performance-Efficiency Trade-off of Low-Precision Numerical
               Formats in Deep Neural Networks}},
  booktitle = {{Proceedings of the Conference for Next Generation Arithmetic
               2019}},
  author    = {Carmichael, Zachariah and Langroudi, Hamed F and Khazanov, Char
               and Lillie, Jeffrey and Gustafson, John L and Kudithipudi,
               Dhireesha},
  abstract  = {Deep neural networks (DNNs) have been demonstrated as effective
               prognostic models across various domains, e.g. natural language
               processing, computer vision, and genomics. However, modern-day
               DNNs demand high compute and memory storage for executing any
               reasonably complex task. To optimize the inference time and
               alleviate the power consumption of these networks, DNN
               accelerators with low-precision representations of data and DNN
               parameters are being actively studied. An interesting research
               question is in how low-precision networks can be ported to
               edge-devices with similar performance as high-precision
               networks. In this work, we employ the fixed-point, floating
               point, and posit numerical formats at $\leq$8-bit precision
               within a DNN accelerator, Deep Positron, with exact
               multiply-and-accumulate (EMAC) units for inference. A unified
               analysis quantifies the trade-offs between overall network
               efficiency and performance across five classification tasks. Our
               results indicate that posits are a natural fit for DNN
               inference, outperforming at $\leq$8-bit precision, and can be
               realized with competitive resource requirements relative to
               those of floating point.},
  publisher = {Association for Computing Machinery},
  number    = {Article 3},
  pages     = {1--9},
  series    = {CoNGA'19},
  month     = mar,
  year      = 2019,
  address   = {New York, NY, USA},
  keywords  = {posit numerical format, machine learning, deep neural networks,
               DNN accelerators, tapered precision, low-precision, floating
               point},
  location  = {Singapore, Singapore},
  isbn      = {9781450371391},
  doi       = {10.1145/3316279.3316282}
}

@inproceedings{Chatelain2019-fu,
  title     = {{Automatic Exploration of Reduced Floating-Point Representations
               in Iterative Methods}},
  booktitle = {{Euro-Par 2019: Parallel Processing}},
  author    = {Chatelain, Yohan and Petit, Eric and de Oliveira Castro, Pablo
               and Lartigue, Ghislain and Defour, David},
  abstract  = {With the ever-increasing need for computation of scientific
               applications, new application domains, and major energy
               constraints, the landscape of floating-point computation is
               changing. New floating-point representation formats are emerging
               and there is a need for tools to simulate their impact in legacy
               codes. In this paper, we propose an automatic tool to evaluate
               the effect of adapting the floating point precision for each
               operation over time, which is particularly useful in iterative
               schemes. We present a backend to emulate any IEEE-754
               floating-point operation in lower precision. We tested the
               numerical errors resilience of our solutions thanks to Monte
               Carlo Arithmetic and demonstrated the effectiveness of this
               methodology on YALES2, a large Combustion-CFD HPC code, by
               achieving 28\% to 67\% reduction in communication volume by
               lowering precision.},
  publisher = {Springer International Publishing},
  pages     = {481--494},
  year      = 2019,
  doi       = {10.1007/978-3-030-29400-7\_34}
}

@inproceedings{Chen2018-an,
  title     = {{Exploiting approximate computing for deep learning acceleration}},
  booktitle = {{2018 Design, Automation Test in Europe Conference Exhibition
               (DATE)}},
  author    = {Chen, Chia-Yu and Choi, Jungwook and Gopalakrishnan, Kailash and
               Srinivasan, Viji and Venkataramani, Swagath},
  abstract  = {Deep Neural Networks (DNNs) have emerged as a powerful and
               versatile set of techniques to address challenging artificial
               intelligence (AI) problems. Applications in domains such as
               image/video processing, natural language processing, speech
               synthesis and recognition, genomics and many others have
               embraced deep learning as the foundational technique. DNNs
               achieve superior accuracy for these applications using very
               large models which require 100s of MBs of data storage, ExaOps
               of computation and high bandwidth for data movement. Despite
               advances in computing systems, training state-of-the-art DNNs on
               large datasets takes several days/weeks, directly limiting the
               pace of innovation and adoption. In this paper, we discuss how
               these challenges can be addressed via approximate computing.
               Based on our earlier studies demonstrating that DNNs are
               resilient to numerical errors from approximate computing, we
               present techniques to reduce communication overhead of
               distributed deep learning training via adaptive residual
               gradient compression (AdaComp), and computation cost for deep
               learning inference via Prameterized clipping ACTivation (PACT)
               based network quantization. Experimental evaluation demonstrates
               order of magnitude savings in communication overhead for
               training and computational cost for inference while not
               compromising application accuracy.},
  pages     = {821--826},
  month     = mar,
  year      = 2018,
  keywords  = {Training;Computational modeling;Machine learning;Approximate
               computing;Quantization (signal);Data models;Convolution},
  issn      = {1558-1101},
  doi       = {10.23919/DATE.2018.8342119}
}

@article{Cherubin2020-tt,
  title     = {{Tools for Reduced Precision Computation: A Survey}},
  author    = {Cherubin, Stefano and Agosta, Giovanni},
  abstract  = {The use of reduced precision to improve performance metrics such
               as computation latency and power consumption is a common
               practice in the embedded systems field. This practice is
               emerging as a new trend in High Performance Computing (HPC),
               especially when new error-tolerant applications are considered.
               However, standard compiler frameworks do not support automated
               precision customization, and manual tuning and code
               transformation is the approach usually adopted in most domains.
               In recent years, research have been studying ways to improve the
               automation of this process. This article surveys this body of
               work, identifying the critical steps of this process, the most
               advanced tools available, and the open challenges in this
               research area. We conclude that, while several mature tools
               exist, there is still a gap to close, especially for tools based
               on static analysis rather than profiling, as well as for
               integration within mainstream, industry-strength compiler
               frameworks.},
  journal   = {ACM Comput. Surv.},
  publisher = {Association for Computing Machinery},
  volume    = 53,
  number    = 2,
  pages     = {1--35},
  month     = apr,
  year      = 2020,
  address   = {New York, NY, USA},
  keywords  = {Reduced precision, approximate computing},
  issn      = {0360-0300},
  doi       = {10.1145/3381039}
}

@article{Davatzikos2019-dc,
  title    = {{Machine learning in neuroimaging: Progress and challenges}},
  author   = {Davatzikos, Christos},
  journal  = {Neuroimage},
  volume   = 197,
  pages    = {652--656},
  month    = aug,
  year     = 2019,
  language = {en},
  issn     = {1053-8119, 1095-9572},
  pmid     = {30296563},
  doi      = {10.1016/j.neuroimage.2018.10.003},
  pmc      = {PMC6499712}
}

@inproceedings{Denis2016-ws,
  title     = {{Verificarlo: Checking Floating Point Accuracy through Monte
               Carlo Arithmetic}},
  booktitle = {{2016 IEEE 23nd Symposium on Computer Arithmetic (ARITH)}},
  author    = {Denis, Christophe and De Oliveira Castro, Pablo and Petit, Eric},
  abstract  = {Numerical accuracy of floating point computation is a well
               studied topic which has not made its way to the end-user in
               scientific computing. Yet, it has become a critical issue with
               the recent requirements for code modernization to harness new
               highly parallel hardware and perform higher resolution
               computation. To democratize numerical accuracy analysis, it is
               important to propose tools and methodologies to study large use
               cases in a reliable and automatic way. In this paper, we propose
               verificarlo, an extension to the LLVM compiler to automatically
               use Monte Carlo Arithmetic in a transparent way for the
               end-user. It supports all the major languages including C, C++,
               and Fortran. Unlike source-to-source approaches, our
               implementation captures the influence of compiler optimizations
               on the numerical accuracy. We illustrate how Monte Carlo
               Arithmetic using the verificarlo tool outperforms the existing
               approaches on various use cases and is a step toward automatic
               numerical analysis.},
  pages     = {55--62},
  month     = jul,
  year      = 2016,
  keywords  = {Monte Carlo methods;Numerical models;Optimization;Computational
               modeling;Standards;Instruments;Hardware;floating point
               arithmetic;numerical analysis;Monte Carlo arithmetic;compilers},
  issn      = {1063-6889},
  doi       = {10.1109/ARITH.2016.31}
}

@article{doi:10.1137/18M1207818,
  author   = {Mang, Andreas and Gholami, Amir and Davatzikos, Christos and Biros, George},
  title    = {{CLAIRE: A Distributed-Memory Solver for Constrained Large Deformation Diffeomorphic Image Registration}},
  journal  = {SIAM Journal on Scientific Computing},
  volume   = {41},
  number   = {5},
  pages    = {C548-C584},
  year     = {2019},
  doi      = {10.1137/18M1207818},
  url      = { 
              https://doi.org/10.1137/18M1207818
              
              },
  eprint   = { 
              https://doi.org/10.1137/18M1207818
              
              },
  abstract = { With this work we release CLAIRE, a distributed-memory implementation of an effective solver for constrained large deformation diffeomorphic image registration problems in three dimensions. We consider an optimal control formulation. We invert for a stationary velocity field that parameterizes the deformation map. Our solver is based on a globalized, preconditioned, inexact reduced space Gauss--Newton--Krylov scheme. We exploit state-of-the-art techniques in scientific computing to develop an effective solver that scales to thousands of distributed memory nodes on high-end clusters. We present the formulation, discuss algorithmic features, describe the software package, and introduce an improved preconditioner for the reduced space Hessian to speed up the convergence of our solver. We test registration performance on synthetic and real data. We demonstrate registration accuracy on several neuroimaging datasets. We compare the performance of our scheme against different flavors of the Demons algorithm for diffeomorphic image registration. We study convergence of our preconditioner and our overall algorithm. We report scalability results on state-of-the-art supercomputing platforms. We demonstrate that we can solve registration problems for clinically relevant data sizes in two to four minutes on a standard compute node with 20 cores, attaining excellent data fidelity. With the present work we achieve a speedup of (on average) 5\$\times\$ with a peak performance of up to 17\$\times\$ compared to our former work. }
}

@article{Esteban2019-og,
  title    = {{fMRIPrep: a robust preprocessing pipeline for functional MRI}},
  author   = {Esteban, Oscar and Markiewicz, Christopher J and Blair, Ross W
              and Moodie, Craig A and Isik, A Ilkay and Erramuzpe, Asier and
              Kent, James D and Goncalves, Mathias and DuPre, Elizabeth and
              Snyder, Madeleine and Oya, Hiroyuki and Ghosh, Satrajit S and
              Wright, Jessey and Durnez, Joke and Poldrack, Russell A and
              Gorgolewski, Krzysztof J},
  abstract = {Preprocessing of functional magnetic resonance imaging (fMRI)
              involves numerous steps to clean and standardize the data before
              statistical analysis. Generally, researchers create ad hoc
              preprocessing workflows for each dataset, building upon a large
              inventory of available tools. The complexity of these workflows
              has snowballed with rapid advances in acquisition and processing.
              We introduce fMRIPrep, an analysis-agnostic tool that addresses
              the challenge of robust and reproducible preprocessing for fMRI
              data. fMRIPrep automatically adapts a best-in-breed workflow to
              the idiosyncrasies of virtually any dataset, ensuring
              high-quality preprocessing without manual intervention. By
              introducing visual assessment checkpoints into an iterative
              integration framework for software testing, we show that fMRIPrep
              robustly produces high-quality results on a diverse fMRI data
              collection. Additionally, fMRIPrep introduces less uncontrolled
              spatial smoothness than observed with commonly used preprocessing
              tools. fMRIPrep equips neuroscientists with an easy-to-use and
              transparent preprocessing workflow, which can help ensure the
              validity of inference and the interpretability of results.},
  journal  = {Nat. Methods},
  volume   = 16,
  number   = 1,
  pages    = {111--116},
  month    = jan,
  year     = 2019,
  language = {en},
  issn     = {1548-7091, 1548-7105},
  pmid     = {30532080},
  doi      = {10.1038/s41592-018-0235-4},
  pmc      = {PMC6319393}
}

@article{Fischl2012-bp,
  title    = {{FreeSurfer}},
  author   = {Fischl, Bruce},
  abstract = {FreeSurfer is a suite of tools for the analysis of neuroimaging
              data that provides an array of algorithms to quantify the
              functional, connectional and structural properties of the human
              brain. It has evolved from a package primarily aimed at
              generating surface representations of the cerebral cortex into
              one that automatically creates models of most macroscopically
              visible structures in the human brain given any reasonable
              T1-weighted input image. It is freely available, runs on a wide
              variety of hardware and software platforms, and is open source.},
  journal  = {Neuroimage},
  volume   = 62,
  number   = 2,
  pages    = {774--781},
  month    = aug,
  year     = 2012,
  language = {en},
  issn     = {1053-8119, 1095-9572},
  pmid     = {22248573},
  doi      = {10.1016/j.neuroimage.2012.01.021},
  pmc      = {PMC3685476}
}

@article{Garyfallidis2014-ve,
  title    = {{Dipy, a library for the analysis of diffusion MRI data}},
  author   = {Garyfallidis, Eleftherios and Brett, Matthew and Amirbekian,
              Bagrat and Rokem, Ariel and van der Walt, Stefan and Descoteaux,
              Maxime and Nimmo-Smith, Ian and {Dipy Contributors}},
  abstract = {Diffusion Imaging in Python (Dipy) is a free and open source
              software project for the analysis of data from diffusion magnetic
              resonance imaging (dMRI) experiments. dMRI is an application of
              MRI that can be used to measure structural features of brain
              white matter. Many methods have been developed to use dMRI data
              to model the local configuration of white matter nerve fiber
              bundles and infer the trajectory of bundles connecting different
              parts of the brain. Dipy gathers implementations of many
              different methods in dMRI, including: diffusion signal
              pre-processing; reconstruction of diffusion distributions in
              individual voxels; fiber tractography and fiber track
              post-processing, analysis and visualization. Dipy aims to provide
              transparent implementations for all the different steps of dMRI
              analysis with a uniform programming interface. We have
              implemented classical signal reconstruction techniques, such as
              the diffusion tensor model and deterministic fiber tractography.
              In addition, cutting edge novel reconstruction techniques are
              implemented, such as constrained spherical deconvolution and
              diffusion spectrum imaging (DSI) with deconvolution, as well as
              methods for probabilistic tracking and original methods for
              tractography clustering. Many additional utility functions are
              provided to calculate various statistics, informative
              visualizations, as well as file-handling routines to assist in
              the development and use of novel techniques. In contrast to many
              other scientific software projects, Dipy is not being developed
              by a single research group. Rather, it is an open project that
              encourages contributions from any scientist/developer through
              GitHub and open discussions on the project mailing list.
              Consequently, Dipy today has an international team of
              contributors, spanning seven different academic institutions in
              five countries and three continents, which is still growing.},
  journal  = {Front. Neuroinform.},
  volume   = 8,
  pages    = {8},
  month    = feb,
  year     = 2014,
  keywords = {DSI; DTI; HARDI; Python; dMRI; diffusion MRI; free open source
              software; tractography},
  language = {en},
  issn     = {1662-5196},
  pmid     = {24600385},
  doi      = {10.3389/fninf.2014.00008},
  pmc      = {PMC3931231}
}

@article{Gustafson2017-wo,
  title     = {{Beating Floating Point at its Own Game: Posit Arithmetic}},
  author    = {{Gustafson} and {Yonemoto}},
  abstract  = {A new data type called a posit is designed as a direct drop-in
               replacement for IEEE Standard 754 floating-point numbers floats.
               Unlike earlier forms of universal number unum arithmetic, posits
               do not require interval arithmetic or variable size operands;
               like floats, they round if an answer is inexact. However, they
               provide compelling advantages over floats, including larger
               dynamic range, higher accuracy, better closure, bitwise
               identical results across systems, simpler hardware, and simpler
               exception handling. Posits never overflow to infinity or
               underflow to zero, and ``Nota-Number'' NaN indicates an action
               instead of a bit pattern. A posit processing unit takes less
               circuitry than an IEEE float FPU. With lower power use and
               smaller silicon footprint, the posit operations per second POPS
               supported by a chip can be significantly higher than the FLOPS
               using similar hardware resources. GPU accelerators and Deep
               Learning processors, in particular, can do more per watt and per
               dollar with posits, yet deliver superior answer quality. A
               comprehensive series of benchmarks compares floats and posits
               for decimals of accuracy produced for a set precision. Low
               precision posits provide a better solution than ``approximate
               computing'' methods that try to tolerate decreased answer
               quality. High precision posits provide more correct decimals
               than floats of the same size; in some cases, a 32-bit posit may
               safely replace a 64-bit float. In other words, posits beat
               floats at their own game.},
  journal   = {Supercomput. Front. Innov.: Int. J.},
  publisher = {South Ural State University},
  volume    = 4,
  number    = 2,
  pages     = {71--86},
  month     = jun,
  year      = 2017,
  address   = {Chelyabinsk, RUS},
  keywords  = {unum computing, posits, neural networks, linear algebra,
               LINPACK, floating point, energy-efficient computing, computer
               arithmetic, valid arithmetic},
  issn      = {2409-6008},
  doi       = {10.14529/jsfi170206}
}


@article{Henschel2020-vq,
  title    = {{FastSurfer - A fast and accurate deep learning based neuroimaging
              pipeline}},
  author   = {Henschel, Leonie and Conjeti, Sailesh and Estrada, Santiago and
              Diers, Kersten and Fischl, Bruce and Reuter, Martin},
  abstract = {Traditional neuroimage analysis pipelines involve computationally
              intensive, time-consuming optimization steps, and thus, do not
              scale well to large cohort studies with thousands or tens of
              thousands of individuals. In this work we propose a fast and
              accurate deep learning based neuroimaging pipeline for the
              automated processing of structural human brain MRI scans,
              replicating FreeSurfer's anatomical segmentation including
              surface reconstruction and cortical parcellation. To this end, we
              introduce an advanced deep learning architecture capable of
              whole-brain segmentation into 95 classes. The network
              architecture incorporates local and global competition via
              competitive dense blocks and competitive skip pathways, as well
              as multi-slice information aggregation that specifically tailor
              network performance towards accurate segmentation of both
              cortical and subcortical structures. Further, we perform fast
              cortical surface reconstruction and thickness analysis by
              introducing a spectral spherical embedding and by directly
              mapping the cortical labels from the image to the surface. This
              approach provides a full FreeSurfer alternative for volumetric
              analysis (in under 1 ​min) and surface-based thickness analysis
              (within only around 1 ​h runtime). For sustainability of this
              approach we perform extensive validation: we assert high
              segmentation accuracy on several unseen datasets, measure
              generalizability and demonstrate increased test-retest
              reliability, and high sensitivity to group differences in
              dementia.},
  journal  = {Neuroimage},
  volume   = 219,
  pages    = {117012},
  month    = oct,
  year     = 2020,
  keywords = {Artificial intelligence; Computational neuroimaging; Deep
              learning; Freesurfer; Structural MRI},
  language = {en},
  issn     = {1053-8119, 1095-9572},
  pmid     = {32526386},
  doi      = {10.1016/j.neuroimage.2020.117012},
  pmc      = {PMC7898243}
}


@article{Higham2019-yd,
  title     = {{Simulating Low Precision Floating-Point Arithmetic}},
  author    = {Higham, Nicholas J and Pranesh, Srikara},
  abstract  = {The half-precision (fp16) floating-point format, defined in the
               2008 revision of the IEEE standard for floating-point
               arithmetic, and a more recently proposed half-precision format
               bfloat16, are increasingly available in GPUs and other
               accelerators. While the support for low precision arithmetic is
               mainly motivated by machine learning applications, general
               purpose numerical algorithms can benefit from it, too, gaining
               in speed, energy usage, and reduced communication costs. Since
               the appropriate hardware is not always available, and one may
               wish to experiment with new arithmetics not yet implemented in
               hardware, software simulations of low precision arithmetic are
               needed. We discuss how to simulate low precision arithmetic
               using arithmetic of higher precision. We examine the correctness
               of such simulations and explain via rounding error analysis why
               a natural method of simulation can provide results that are more
               accurate than actual computations at low precision. We provide a
               MATLAB function, chop, that can be used to efficiently simulate
               fp16, bfloat16, and other low precision arithmetics, with or
               without the representation of subnormal numbers and with the
               options of round to nearest, directed rounding, stochastic
               rounding, and random bit flips in the significand. We
               demonstrate the advantages of this approach over defining a new
               MATLAB class and overloading operators.},
  journal   = {SIAM J. Sci. Comput.},
  publisher = {Society for Industrial and Applied Mathematics},
  volume    = 41,
  number    = 5,
  pages     = {C585--C602},
  month     = jan,
  year      = 2019,
  issn      = {1064-8275},
  doi       = {10.1137/19M1251308}
}

@misc{intel-BF16-2018,
  title        = {{BFLOAT16 - Hardware Numerics Definition}},
  url          = {https://www.intel.com/content/dam/develop/external/us/en/documents/bf16-hardware-numerics-definition-white-paper.pdf},
  howpublished = {\url{https://www.intel.com/content/dam/develop/external/us/en/documents/bf16-hardware-numerics-definition-white-paper.pdf}},
  journal      = {Intel},
  publisher    = {Intel},
  author       = {Intel},
  year         = {2018},
  month        = {Nov}
}

@article{Johnson2018-up,
  title         = {{Rethinking floating point for deep learning}},
  author        = {Johnson, Jeff},
  abstract      = {Reducing hardware overhead of neural networks for faster or
                   lower power inference and training is an active area of
                   research. Uniform quantization using integer multiply-add
                   has been thoroughly investigated, which requires learning
                   many quantization parameters, fine-tuning training or other
                   prerequisites. Little effort is made to improve floating
                   point relative to this baseline; it remains energy
                   inefficient, and word size reduction yields drastic loss in
                   needed dynamic range. We improve floating point to be more
                   energy efficient than equivalent bit width integer hardware
                   on a 28 nm ASIC process while retaining accuracy in 8 bits
                   with a novel hybrid log multiply/linear add, Kulisch
                   accumulation and tapered encodings from Gustafson's posit
                   format. With no network retraining, and drop-in replacement
                   of all math and float32 parameters via round-to-nearest-even
                   only, this open-sourced 8-bit log float is within 0.9\%
                   top-1 and 0.2\% top-5 accuracy of the original float32
                   ResNet-50 CNN model on ImageNet. Unlike int8 quantization,
                   it is still a general purpose floating point arithmetic,
                   interpretable out-of-the-box. Our 8/38-bit log float
                   multiply-add is synthesized and power profiled at 28 nm at
                   0.96x the power and 1.12x the area of 8/32-bit integer
                   multiply-add. In 16 bits, our log float multiply-add is
                   0.59x the power and 0.68x the area of IEEE 754 float16 fused
                   multiply-add, maintaining the same signficand precision and
                   dynamic range, proving useful for training ASICs as well.},
  month         = nov,
  year          = 2018,
  archiveprefix = {arXiv},
  eprint        = {1811.01721},
  primaryclass  = {cs.NA},
  arxivid       = {1811.01721},
  journal       = {arXiv}
}

@article{Judd2015-kw,
  title         = {{Reduced-Precision Strategies for Bounded Memory in Deep
                   Neural Nets}},
  author        = {Judd, Patrick and Albericio, Jorge and Hetherington, Tayler
                   and Aamodt, Tor and Jerger, Natalie Enright and Urtasun,
                   Raquel and Moshovos, Andreas},
  abstract      = {This work investigates how using reduced precision data in
                   Convolutional Neural Networks (CNNs) affects network
                   accuracy during classification. More specifically, this
                   study considers networks where each layer may use different
                   precision data. Our key result is the observation that the
                   tolerance of CNNs to reduced precision data not only varies
                   across networks, a well established observation, but also
                   within networks. Tuning precision per layer is appealing as
                   it could enable energy and performance improvements. In this
                   paper we study how error tolerance across layers varies and
                   propose a method for finding a low precision configuration
                   for a network while maintaining high accuracy. A diverse set
                   of CNNs is analyzed showing that compared to a conventional
                   implementation using a 32-bit floating-point representation
                   for all layers, and with less than 1\% loss in relative
                   accuracy, the data footprint required by these networks can
                   be reduced by an average of 74\% and up to 92\%.},
  month         = nov,
  year          = 2015,
  archiveprefix = {arXiv},
  eprint        = {1511.05236},
  primaryclass  = {cs.LG},
  arxivid       = {1511.05236},
  journal       = {arXiv}
}

@article{Kiar2020-uv,
  title    = {{Comparing perturbation models for evaluating stability of
              neuroimaging pipelines}},
  author   = {Kiar, Gregory and de Oliveira Castro, Pablo and Rioux, Pierre and
              Petit, Eric and Brown, Shawn T and Evans, Alan C and Glatard,
              Tristan},
  abstract = {With an increase in awareness regarding a troubling lack of
              reproducibility in analytical software tools, the degree of
              validity in scientific derivatives and their downstream results
              has become unclear. The nature of reproducibility issues may vary
              across domains, tools, data sets, and computational
              infrastructures, but numerical instabilities are thought to be a
              core contributor. In neuroimaging, unexpected deviations have
              been observed when varying operating systems, software
              implementations, or adding negligible quantities of noise. In the
              field of numerical analysis, these issues have recently been
              explored through Monte Carlo Arithmetic, a method involving the
              instrumentation of floating-point operations with probabilistic
              noise injections at a target precision. Exploring multiple
              simulations in this context allows the characterization of the
              result space for a given tool or operation. In this article, we
              compare various perturbation models to introduce instabilities
              within a typical neuroimaging pipeline, including (i) targeted
              noise, (ii) Monte Carlo Arithmetic, and (iii) operating system
              variation, to identify the significance and quality of their
              impact on the resulting derivatives. We demonstrate that even
              low-order models in neuroimaging such as the structural
              connectome estimation pipeline evaluated here are sensitive to
              numerical instabilities, suggesting that stability is a relevant
              axis upon which tools are compared, alongside more traditional
              criteria such as biological feasibility, computational
              efficiency, or, when possible, accuracy. Heterogeneity was
              observed across participants which clearly illustrates a strong
              interaction between the tool and data set being processed,
              requiring that the stability of a given tool be evaluated with
              respect to a given cohort. We identify use cases for each
              perturbation method tested, including quality assurance, pipeline
              error detection, and local sensitivity analysis, and make
              recommendations for the evaluation of stability in a practical
              and analytically focused setting. Identifying how these
              relationships and recommendations scale to higher order
              computational tools, distinct data sets, and their implication on
              biological feasibility remain exciting avenues for future work.},
  journal  = {Int. J. High Perform. Comput. Appl.},
  volume   = 34,
  number   = 5,
  pages    = {491--501},
  month    = sep,
  year     = 2020,
  keywords = {Monte Carlo Arithmetic; Neuroimaging; diffusion MRI; stability},
  language = {en},
  issn     = {1094-3420},
  pmid     = {32831546},
  doi      = {10.1177/1094342020926237},
  pmc      = {PMC7418878}
}

@article{Kingsbury1971-kx,
  title     = {{Digital filtering using logarithmic arithmetic}},
  author    = {Kingsbury, Nick G and Rayner, Peter J W},
  abstract  = {A method of computation is described in which all signals are
               encoded logarithmically, giving a great improvement in dynamic
               range compared with fixed-point linearly encoded arithmetic. Two
               ways of adding or subtracting logarithmically encoded numbers
               are suggested, together with a logarithmic digital-analogue
               convertor.},
  journal   = {Electron. Lett.},
  publisher = {IET},
  volume    = 7,
  number    = 2,
  pages     = {56--58},
  year      = 1971,
  issn      = {0013-5194}
}

@article{Le_Bihan2015-vp,
  title    = {{Diffusion Magnetic Resonance Imaging: What Water Tells Us about
              Biological Tissues}},
  author   = {Le Bihan, Denis and Iima, Mami},
  abstract = {Since its introduction in the mid-1980s, diffusion magnetic
              resonance imaging (MRI), which measures the random motion of
              water molecules in tissues, revealing their microarchitecture,
              has become a pillar of modern neuroimaging. Its main clinical
              domain has been the diagnosis of acute brain stroke and
              neurogical disorders, but it is also used in the body for the
              detection and management of cancer lesions. It can also produce
              stunning maps of white matter tracks in the brain, with the
              potential to aid in the understanding of some psychiatric
              disorders. However, in order to exploit fully the potential of
              this method, a deeper understanding of the mechanisms that govern
              the diffusion of water in tissues is needed.},
  journal  = {PLoS Biol.},
  volume   = 13,
  number   = 7,
  pages    = {e1002203},
  month    = jul,
  year     = 2015,
  language = {en},
  issn     = {1544-9173, 1545-7885},
  pmid     = {26204162},
  doi      = {10.1371/journal.pbio.1002203},
  pmc      = {PMC4512706}
} 

@article{Lesser2011-mn,
  title     = {{Effects of Reduced Precision on Floating-Point SVM
               Classification Accuracy}},
  author    = {Lesser, Bernd and M{\"u}cke, Manfred and Gansterer, Wilfried N},
  abstract  = {There is growing interest in performing ever more complex
               classification tasks on mobile and embedded devices in
               real-time, which results in the need for e\_cient
               implementations of the respective algorithms. Support vector
               machines (SVMs) represent a powerful class of nonlinear
               classifiers, and reducing the working precision represents a
               promising approach to achieving e\_cient implementations of the
               SVM classification phase. However, the relationship between SVM
               classification accuracy and the arithmetic precision used is not
               yet su\_ciently understood. We investigate this relationship in
               floating-point arithmetic and illustrate that often a large
               reduction in the working precision of the classification process
               is possible without loss in classification accuracy. Moreover,
               we investigate the adaptation of bounds on allowable SVM
               parameter perturbations in order to estimate the lowest possible
               working precision in floating-point arithmetic. Among the three
               representative data sets considered in this paper, none requires
               a precision higher than 15 bit, which is a considerable
               reduction from the 53 bit used in double precision
               floating-point arithmetic. Furthermore, we demonstrate analytic
               bounds on the working precision for SVMs with Gaussian kernel
               providing good predictions of possible reductions in the working
               precision without sacrificing classification accuracy.},
  journal   = {Procedia Comput. Sci.},
  publisher = {Elsevier},
  volume    = 4,
  pages     = {508--517},
  month     = jan,
  year      = 2011,
  keywords  = {SVM; machine learning; reduced precision floating-point
               arithmetic; perturbation analysis; quantization effects},
  issn      = {1877-0509},
  doi       = {10.1016/j.procs.2011.04.053}
} 

@article{Li2021-rv,
  title    = {{Whole brain segmentation with full volume neural network}},
  author   = {Li, Yeshu and Cui, Jonathan and Sheng, Yilun and Liang, Xiao and
              Wang, Jingdong and Chang, Eric I-Chao and Xu, Yan},
  abstract = {Whole brain segmentation is an important neuroimaging task that
              segments the whole brain volume into anatomically labeled
              regions-of-interest. Convolutional neural networks have
              demonstrated good performance in this task. Existing solutions,
              usually segment the brain image by classifying the voxels, or
              labeling the slices or the sub-volumes separately. Their
              representation learning is based on parts of the whole volume
              whereas their labeling result is produced by aggregation of
              partial segmentation. Learning and inference with incomplete
              information could lead to sub-optimal final segmentation result.
              To address these issues, we propose to adopt a full volume
              framework, which feeds the full volume brain image into the
              segmentation network and directly outputs the segmentation result
              for the whole brain volume. The framework makes use of complete
              information in each volume and can be implemented easily. An
              effective instance in this framework is given subsequently. We
              adopt the 3D high-resolution network (HRNet) for learning
              spatially fine-grained representations and the mixed precision
              training scheme for memory-efficient training. Extensive
              experiment results on a publicly available 3D MRI brain dataset
              show that our proposed model advances the state-of-the-art
              methods in terms of segmentation performance.},
  journal  = {Comput. Med. Imaging Graph.},
  volume   = 93,
  pages    = {101991},
  month    = oct,
  year     = 2021,
  keywords = {Brain; Deep learning; Neural networks; Segmentation},
  language = {en},
  issn     = {0895-6111, 1879-0771},
  pmid     = {34634548},
  doi      = {10.1016/j.compmedimag.2021.101991}
}


@article{Li2021.12.01.470790,
  author       = {Li, Xinhui and Ai, Lei and Giavasis, Steve and Jin, Hecheng and Feczko, Eric and Xu, Ting and Clucas, Jon and Franco, Alexandre and S{\'o}lon Heinsfeld, Anibal and Adebimpe, Azeez and Vogelstein, Joshua T. and Yan, Chao-Gan and Esteban, Oscar and Poldrack, Russell A. and Craddock, Cameron and Fair, Damien and Satterthwaite, Theodore and Kiar, Gregory and Milham, Michael P.},
  title        = {Moving Beyond Processing and Analysis-Related Variation in Neuroscience},
  elocation-id = {2021.12.01.470790},
  year         = {2021},
  doi          = {10.1101/2021.12.01.470790},
  publisher    = {Cold Spring Harbor Laboratory},
  abstract     = {When fields lack consensus standards and ground truths for their analytic methods, reproducibility tends to be more of an ideal than a reality. Such has been the case for functional neuroimaging, where there exists a sprawling space of tools from which scientists can construct processing pipelines and draw interpretations. We provide a critical evaluation of the impact of differences observed in results across five independently developed functional MRI minimal preprocessing pipelines. We show that even when handling the same exact data, inter-pipeline agreement was only moderate, with the specific steps that contribute to the lack of agreement varying across pipeline comparisons. Using a densely sampled test-retest dataset, we show that the limitations imposed by inter-pipeline agreement mainly become appreciable when the reliability of the underlying data is high. We highlight the importance of comparison among analytic tools and parameters, as both widely debated (e.g., global signal regression) and commonly overlooked (e.g., MNI template version) decisions were each found to lead to marked variation. We provide recommendations for incorporating tool-based variability in functional neuroimaging analyses and a supporting infrastructure.Competing Interest StatementThe authors have declared no competing interest.},
  url          = {https://www.biorxiv.org/content/early/2021/12/03/2021.12.01.470790},
  eprint       = {https://www.biorxiv.org/content/early/2021/12/03/2021.12.01.470790.full.pdf},
  journal      = {bioRxiv}
}

@inproceedings{Long2015-qr,
  title     = {{Fully convolutional networks for semantic segmentation}},
  booktitle = {{2015 IEEE Conference on Computer Vision and Pattern Recognition
               (CVPR)}},
  author    = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  abstract  = {Convolutional networks are powerful visual models that yield
               hierarchies of features. We show that convolutional networks by
               themselves, trained end-to-end, pixels-to-pixels, exceed the
               state-of-the-art in semantic segmentation. Our key insight is to
               build ``fully convolutional'' networks that take input of
               arbitrary size and produce correspondingly-sized output with
               efficient inference and learning. We define and detail the space
               of fully convolutional networks, explain their application to
               spatially dense prediction tasks, and draw connections to prior
               models. We adapt contemporary classification networks (AlexNet
               [20], the VGG net [31], and GoogLeNet [32]) into fully
               convolutional networks and transfer their learned
               representations by fine-tuning [3] to the segmentation task. We
               then define a skip architecture that combines semantic
               information from a deep, coarse layer with appearance
               information from a shallow, fine layer to produce accurate and
               detailed segmentations. Our fully convolutional network achieves
               state-of-the-art segmentation of PASCAL VOC (20\% relative
               improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow,
               while inference takes less than one fifth of a second for a
               typical image.},
  pages     = {3431--3440},
  month     = jun,
  year      = 2015,
  keywords  = {Semantics;Training;Convolution;Image segmentation;Computer
               architecture;Deconvolution;Adaptation models},
  issn      = {1063-6919},
  doi       = {10.1109/CVPR.2015.7298965}
}

@article{Mateos-Perez2018-wx,
  title    = {{Structural neuroimaging as clinical predictor: A review of
              machine learning applications}},
  author   = {Mateos-P{\'e}rez, Jos{\'e} Mar{\'\i}a and Dadar, Mahsa and
              Lacalle-Aurioles, Mar{\'\i}a and Iturria-Medina, Yasser and
              Zeighami, Yashar and Evans, Alan C},
  abstract = {In this paper, we provide an extensive overview of machine
              learning techniques applied to structural magnetic resonance
              imaging (MRI) data to obtain clinical classifiers. We
              specifically address practical problems commonly encountered in
              the literature, with the aim of helping researchers improve the
              application of these techniques in future works. Additionally, we
              survey how these algorithms are applied to a wide range of
              diseases and disorders (e.g. Alzheimer's disease (AD),
              Parkinson's disease (PD), autism, multiple sclerosis, traumatic
              brain injury, etc.) in order to provide a comprehensive view of
              the state of the art in different fields.},
  journal  = {Neuroimage Clin},
  volume   = 20,
  pages    = {506--522},
  month    = aug,
  year     = 2018,
  keywords = {Alzheimer; Autism; Cross-validation; Ensembling; Machine
              learning; Multiple sclerosis; Neuroimaging; Parkinson; Predictive
              modeling; SVMs; Structural magnetic resonance imaging},
  language = {en},
  issn     = {2213-1582},
  pmid     = {30167371},
  doi      = {10.1016/j.nicl.2018.08.019},
  pmc      = {PMC6108077}
}


@article{Molloy2014-oc,
  title    = {{The influence of spatial resolution and smoothing on the
              detectability of resting-state and task fMRI}},
  author   = {Molloy, Erin K and Meyerand, Mary E and Birn, Rasmus M},
  abstract = {Functional MRI blood oxygen level-dependent (BOLD) signal changes
              can be subtle, motivating the use of imaging parameters and
              processing strategies that maximize the temporal signal-to-noise
              ratio (tSNR) and thus the detection power of neuronal
              activity-induced fluctuations. Previous studies have shown that
              acquiring data at higher spatial resolutions results in greater
              percent BOLD signal changes, and furthermore that spatially
              smoothing higher resolution fMRI data improves tSNR beyond that
              of data originally acquired at a lower resolution. However,
              higher resolution images come at the cost of increased
              acquisition time, and the number of image volumes also influences
              detectability. The goal of our study is to determine how the
              detection power of neuronally induced BOLD fluctuations acquired
              at higher spatial resolutions and then spatially smoothed
              compares to data acquired at the lower resolutions with the same
              imaging duration. The number of time points acquired during a
              given amount of imaging time is a practical consideration given
              the limited ability of certain populations to lie still in the
              MRI scanner. We compare acquisitions at three different in-plane
              spatial resolutions (3.50$\times$3.50mm(2),
              2.33$\times$2.33mm(2), 1.75$\times$1.75mm(2)) in terms of their
              tSNR, contrast-to-noise ratio, and the power to detect both
              task-related activation and resting-state functional
              connectivity. The impact of SENSE acceleration, which speeds up
              acquisition time increasing the number of images collected, is
              also evaluated. Our results show that after spatially smoothing
              the data to the same intrinsic resolution, lower resolution
              acquisitions have a slightly higher detection power of
              task-activation in some, but not all, brain areas. There were no
              significant differences in functional connectivity as a function
              of resolution after smoothing. Similarly, the reduced tSNR of
              fMRI data acquired with a SENSE factor of 2 is offset by the
              greater number of images acquired, resulting in few significant
              differences in detection power of either functional activation or
              connectivity after spatial smoothing.},
  journal  = {Neuroimage},
  volume   = 86,
  pages    = {221--230},
  month    = feb,
  year     = 2014,
  keywords = {Detection power; Functional MRI; Functional connectivity;
              Resolution; SENSE; Spatial smoothing},
  language = {en},
  issn     = {1053-8119, 1095-9572},
  pmid     = {24021836},
  doi      = {10.1016/j.neuroimage.2013.09.001},
  pmc      = {PMC5736131}
}

@article{Morris1971-qg,
  title    = {{Tapered Floating Point: A New Floating-Point Representation}},
  author   = {Morris, R},
  abstract = {It is well known that there is a possible tradeoff in the binary
              representation of floating-point numbers in which one bit of
              accuracy can be gained at the cost of halving the exponent range,
              and vice versa. A way in which the exponent range can be greatly
              increased while preserving full accuracy for most computations is
              suggested.},
  journal  = {IEEE Trans. Comput.},
  volume   = {C-20},
  number   = 12,
  pages    = {1578--1579},
  month    = dec,
  year     = 1971,
  keywords = {Acuracy, exponent range, floating point, number representation.},
  issn     = {0018-9340, 1557-9956},
  doi      = {10.1109/T-C.1971.223174}
}

@book{Muller2018-zm,
  title     = {{Handbook of Floating-Point Arithmetic}},
  author    = {Muller, Jean-Michel and Brunie, Nicolas and de Dinechin, Florent
               and Jeannerod, Claude-Pierre and Joldes, Mioara and Lef{\`e}vre,
               Vincent and Melquiond, Guillaume and Revol, Nathalie and Torres,
               Serge},
  publisher = {Birkh{\"a}user, Cham},
  year      = 2018,
  isbn      = {9783319765259, 9783319765266},
  doi       = {10.1007/978-3-319-76526-6}
}

@article{Nguyen2018-lo,
  title         = {{False discovery rate control under reduced precision
                   computation for analysis of neuroimaging data}},
  author        = {Nguyen, Hien D and Yee, Yohan and McLachlan, Geoffrey J and
                   Lerch, Jason P},
  abstract      = {The mitigation of false positives is an important issue when
                   conducting multiple hypothesis testing. The most popular
                   paradigm for false positives mitigation in high-dimensional
                   applications is via the control of the false discovery rate
                   (FDR). Multiple testing data from neuroimaging experiments
                   can be very large, and reduced precision storage of such
                   data is often required. Reduced precision computation is
                   often a problem in the analysis of legacy data and data
                   arising from legacy pipelines. We present a method for FDR
                   control that is applicable in cases where only
                   p\textbackslashtext\{-values\} or test statistics (with
                   common and known null distribution) are available, and when
                   those p\textbackslashtext\{-values\} or test statistics are
                   encoded in a reduced precision format. Our method is based
                   on an empirical-Bayes paradigm where the probit
                   transformation of the p\textbackslashtext\{-values\} (called
                   the z\textbackslashtext\{-scores\}) are modeled as a
                   two-component mixture of normal distributions. Due to the
                   reduced precision of the p\textbackslashtext\{-values\} or
                   test statistics, the usual approach for fitting mixture
                   models may not be feasible. We instead use a binned-data
                   technique, which can be proved to consistently estimate the
                   z\textbackslashtext\{-score\} distribution parameters under
                   mild correlation assumptions, as is often the case in
                   neuroimaging data. A simulation study shows that our
                   methodology is competitive when compared with popular
                   alternatives, especially with data in the presence of
                   misspecification. We demonstrate the applicability of our
                   methodology in practice via a brain imaging study of mice.},
  month         = may,
  year          = 2018,
  archiveprefix = {arXiv},
  eprint        = {1805.04394},
  primaryclass  = {stat.ME},
  arxivid       = {1805.04394},
  journal       = {arXiv}
}

@inproceedings{Nie2016-sw,
  title     = {{3D Deep Learning for Multi-modal Imaging-Guided Survival Time
               Prediction of Brain Tumor Patients}},
  booktitle = {{Medical Image Computing and Computer-Assisted Intervention --
               MICCAI 2016}},
  author    = {Nie, Dong and Zhang, Han and Adeli, Ehsan and Liu, Luyan and
               Shen, Dinggang},
  abstract  = {High-grade glioma is the most aggressive and severe brain tumor
               that leads to death of almost 50 \% patients in 1--2 years.
               Thus, accurate prognosis for glioma patients would provide
               essential guidelines for their treatment planning. Conventional
               survival prediction generally utilizes clinical information and
               limited handcrafted features from magnetic resonance images
               (MRI), which is often time consuming, laborious and subjective.
               In this paper, we propose using deep learning frameworks to
               automatically extract features from multi-modal preoperative
               brain images (i.e., T1 MRI, fMRI and DTI) of high-grade glioma
               patients. Specifically, we adopt 3D convolutional neural
               networks (CNNs) and also propose a new network architecture for
               using multi-channel data and learning supervised features. Along
               with the pivotal clinical features, we finally train a support
               vector machine to predict if the patient has a long or short
               overall survival (OS) time. Experimental results demonstrate
               that our methods can achieve an accuracy as high as 89.9 \% We
               also find that the learned features from fMRI and DTI play more
               important roles in accurately predicting the OS time, which
               provides valuable insights into functional neuro-oncological
               applications.},
  publisher = {Springer International Publishing},
  pages     = {212--220},
  year      = 2016,
  doi       = {10.1007/978-3-319-46723-8\_25}
}

@article{Paszke2019-sm,
  title         = {{PyTorch: An imperative style, high-performance deep learning
                   library}},
  author        = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                   Adam and Bradbury, James and Chanan, Gregory and Killeen,
                   Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                   Luca and Desmaison, Alban and K{\"o}pf, Andreas and Yang,
                   Edward and DeVito, Zach and Raison, Martin and Tejani,
                   Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and
                   Fang, Lu and Bai, Junjie and Chintala, Soumith},
  abstract      = {Deep learning frameworks have often focused on either
                   usability or speed, but not both. PyTorch is a machine
                   learning library that shows that these two goals are in fact
                   compatible: it provides an imperative and Pythonic
                   programming style that supports code as a model, makes
                   debugging easy and is consistent with other popular
                   scientific computing libraries, while remaining efficient
                   and supporting hardware accelerators such as GPUs. In this
                   paper, we detail the principles that drove the
                   implementation of PyTorch and how they are reflected in its
                   architecture. We emphasize that every aspect of PyTorch is a
                   regular Python program under the full control of its user.
                   We also explain how the careful and pragmatic implementation
                   of the key components of its runtime enables them to work
                   together to achieve compelling performance. We demonstrate
                   the efficiency of individual subsystems, as well as the
                   overall speed of PyTorch on several common benchmarks.},
  month         = dec,
  year          = 2019,
  copyright     = {http://arxiv.org/licenses/nonexclusive-distrib/1.0/},
  archiveprefix = {arXiv},
  eprint        = {1912.01703},
  primaryclass  = {cs.LG},
  arxivid       = {1912.01703},
  journal       = {arXiv}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@inproceedings{Ronneberger2015-wy,
  title     = {{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
  booktitle = {{Medical Image Computing and Computer-Assisted Intervention --
               MICCAI 2015}},
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  abstract  = {There is large consent that successful training of deep networks
               requires many thousand annotated training samples. In this
               paper, we present a network and training strategy that relies on
               the strong use of data augmentation to use the available
               annotated samples more efficiently. The architecture consists of
               a contracting path to capture context and a symmetric expanding
               path that enables precise localization. We show that such a
               network can be trained end-to-end from very few images and
               outperforms the prior best method (a sliding-window
               convolutional network) on the ISBI challenge for segmentation of
               neuronal structures in electron microscopic stacks. Using the
               same network trained on transmitted light microscopy images
               (phase contrast and DIC) we won the ISBI cell tracking challenge
               2015 in these categories by a large margin. Moreover, the
               network is fast. Segmentation of a 512x512 image takes less than
               a second on a recent GPU. The full implementation (based on
               Caffe) and the trained networks are available at
               http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  publisher = {Springer International Publishing},
  pages     = {234--241},
  year      = 2015,
  doi       = {10.1007/978-3-319-24574-4\_28}
}

@article{Salari2021-kd,
  title         = {{Accurate simulation of operating system updates in
                   neuroimaging using Monte-Carlo arithmetic}},
  author        = {Salari, Ali and Chatelain, Yohan and Kiar, Gregory and
                   Glatard, Tristan},
  abstract      = {Operating system (OS) updates introduce numerical
                   perturbations that impact the reproducibility of
                   computational pipelines. In neuroimaging, this has important
                   practical implications on the validity of computational
                   results, particularly when obtained in systems such as
                   high-performance computing clusters where the experimenter
                   does not control software updates. We present a framework to
                   reproduce the variability induced by OS updates in
                   controlled conditions. We hypothesize that OS updates impact
                   computational pipelines mainly through numerical
                   perturbations originating in mathematical libraries, which
                   we simulate using Monte-Carlo arithmetic in a framework
                   called ``fuzzy libmath'' (FL). We applied this methodology
                   to pre-processing pipelines of the Human Connectome Project,
                   a flagship open-data project in neuroimaging. We found that
                   FL-perturbed pipelines accurately reproduce the variability
                   induced by OS updates and that this similarity is only
                   mildly dependent on simulation parameters. Importantly, we
                   also found between-subject differences were preserved in
                   both cases, though the between-run variability was of
                   comparable magnitude for both FL and OS perturbations. We
                   found the numerical precision in the HCP pre-processed
                   images to be relatively low, with less than 8 significant
                   bits among the 24 available, which motivates further
                   investigation of the numerical stability of components in
                   the tested pipeline. Overall, our results establish that FL
                   accurately simulates results variability due to OS updates,
                   and is a practical framework to quantify numerical
                   uncertainty in neuroimaging.},
  month         = aug,
  year          = 2021,
  archiveprefix = {arXiv},
  eprint        = {2108.03129},
  primaryclass  = {q-bio.NC},
  arxivid       = {2108.03129},
  journal       = {arXiv}
}

@article{Scheinost2014-ds,
  title    = {{The impact of image smoothness on intrinsic functional
              connectivity and head motion confounds}},
  author   = {Scheinost, Dustin and Papademetris, Xenophon and Constable, R
              Todd},
  abstract = {We present a novel method for controlling the effects of group
              differences in motion on functional connectivity studies.
              Resting-state functional magnetic resonance imaging (rs-fMRI) is
              a powerful tool that allows for the assessment of whole-brain
              functional organization across a wide range of clinical
              populations. However, as highlighted by recent studies, many
              measures commonly used in rs-fMRI are highly correlated with
              subject head movement. A source of this problem is that motion
              itself, and motion correction algorithms, lead to spatial
              smoothing, which is then variable across the brain and across
              subjects or groups dependent upon the amount of motion present
              during scanning. Studies aimed at elucidating differences between
              populations that have different head-motion characteristics
              (e.g., patients often move more in the scanner than healthy
              control subjects) are significantly confounded by these effects.
              In this work, we propose a solution to this problem, uniform
              smoothing, which ensures that all subject images in a study have
              equal effective spatial resolution. We establish that differences
              in the intrinsic smoothness of images across a group can confound
              connectivity results and link these differences in smoothness to
              motion. We demonstrate that eliminating these smoothness
              differences via our uniform smoothing solution is successful in
              reducing confounds related to the differences in head motion
              between subjects.},
  journal  = {Neuroimage},
  volume   = 95,
  pages    = {13--21},
  month    = jul,
  year     = 2014,
  keywords = {Connectivity; Head movement; Image smoothness; Motion;
              Resting-state fMRI},
  language = {en},
  issn     = {1053-8119, 1095-9572},
  pmid     = {24657356},
  doi      = {10.1016/j.neuroimage.2014.03.035},
  pmc      = {PMC4076413}
}

@article{Soares2013-hw,
  title     = {{A hitchhiker's guide to diffusion tensor imaging}},
  author    = {Soares, Jos{\'e} M and Marques, Paulo and Alves, Victor and
               Sousa, Nuno},
  abstract  = {Diffusion Tensor Imaging (DTI) studies are increasingly popular
               among clinicians and researchers as they provide unique insights
               into brain network connectivity. However, in order to optimize
               the use of DTI, several technical and methodological aspects
               must be factored in. These include decisions on: acquisition
               protocol, artifact handling, data quality control,
               reconstruction algorithm, and visualization approaches, and
               quantitative analysis methodology. Furthermore, the researcher
               and/or clinician also needs to take into account and decide on
               the most suited software tool(s) for each stage of the DTI
               analysis pipeline. Herein, we provide a straightforward
               hitchhiker's guide, covering all of the workflow's major stages.
               Ultimately, this guide will help newcomers navigate the most
               critical roadblocks in the analysis and further encourage the
               use of DTI.},
  journal   = {Front. Neurosci.},
  publisher = {frontiersin.org},
  volume    = 7,
  pages     = {31},
  month     = mar,
  year      = 2013,
  keywords  = {acquisition; analysis; diffusion tensor imaging; hitchhiker's
               guide; processing},
  language  = {en},
  issn      = {1662-4548, 1662-453X},
  pmid      = {23486659},
  doi       = {10.3389/fnins.2013.00031},
  pmc       = {PMC3594764}
}

@article{Soares2016-tz,
  title    = {{A Hitchhiker's Guide to Functional Magnetic Resonance Imaging}},
  author   = {Soares, Jos{\'e} M and Magalh{\~a}es, Ricardo and Moreira, Pedro
              S and Sousa, Alexandre and Ganz, Edward and Sampaio, Adriana and
              Alves, Victor and Marques, Paulo and Sousa, Nuno},
  abstract = {Functional Magnetic Resonance Imaging (fMRI) studies have become
              increasingly popular both with clinicians and researchers as they
              are capable of providing unique insights into brain functions.
              However, multiple technical considerations (ranging from
              specifics of paradigm design to imaging artifacts, complex
              protocol definition, and multitude of processing and methods of
              analysis, as well as intrinsic methodological limitations) must
              be considered and addressed in order to optimize fMRI analysis
              and to arrive at the most accurate and grounded interpretation of
              the data. In practice, the researcher/clinician must choose, from
              many available options, the most suitable software tool for each
              stage of the fMRI analysis pipeline. Herein we provide a
              straightforward guide designed to address, for each of the major
              stages, the techniques, and tools involved in the process. We
              have developed this guide both to help those new to the technique
              to overcome the most critical difficulties in its use, as well as
              to serve as a resource for the neuroimaging community.},
  journal  = {Front. Neurosci.},
  volume   = 10,
  pages    = {515},
  month    = nov,
  year     = 2016,
  keywords = {acquisition; analysis; fMRI; hitchhiker's guide; preprocessing},
  language = {en},
  issn     = {1662-4548, 1662-453X},
  pmid     = {27891073},
  doi      = {10.3389/fnins.2016.00515},
  pmc      = {PMC5102908}
}

@misc{SwampCancel,
  title        = {{Cancellation and Swamping}},
  url          = {https://arnold.hosted.uark.edu/NLA/Pages/SwampCancel.pdf},
  howpublished = {\url{https://arnold.hosted.uark.edu/NLA/Pages/SwampCancel.pdf}},
  author       = {Mark Arnold},
  year         = {2022},
  month        = {May}
}

@article{Symms2004-xj,
  title    = {{A review of structural magnetic resonance neuroimaging}},
  author   = {Symms, M and J{\"a}ger, H R and Schmierer, K and Yousry, T A},
  abstract = {Magnetic resonance imaging (MRI) is often divided into structural
              MRI and functional MRI (fMRI). The former is a widely used
              imaging technique in research as well as in clinical practice.
              This review describes the more important developments in
              structural MRI in recent years, including high resolution
              imaging, T2 relaxation measurement, T2*-weighted imaging, T1
              relaxation measurement, magnetisation transfer imaging, and
              diffusion imaging. The principles underlying these techniques, as
              well as their use in research and in clinical practice, will be
              discussed.},
  journal  = {J. Neurol. Neurosurg. Psychiatry},
  volume   = 75,
  number   = 9,
  pages    = {1235--1244},
  month    = sep,
  year     = 2004,
  language = {en},
  issn     = {0022-3050},
  pmid     = {15314108},
  doi      = {10.1136/jnnp.2003.032714},
  pmc      = {PMC1739217}
}

@misc{tensorflow2015-whitepaper,
  title  = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems}},
  url    = {http://tensorflow.org/},
  note   = {Software available from \url{http://tensorflow.org/}},
  author = {
            Mart\'{\i}n~Abadi and
            Ashish~Agarwal and
            Paul~Barham and
            Eugene~Brevdo and
            Zhifeng~Chen and
            Craig~Citro and
            Greg~S.~Corrado and
            Andy~Davis and
            Jeffrey~Dean and
            Matthieu~Devin and
            Sanjay~Ghemawat and
            Ian~Goodfellow and
            Andrew~Harp and
            Geoffrey~Irving and
            Michael~Isard and
            Yangqing Jia and
            Rafal~Jozefowicz and
            Lukasz~Kaiser and
            Manjunath~Kudlur and
            Josh~Levenberg and
            Dan~Man\'{e} and
            Rajat~Monga and
            Sherry~Moore and
            Derek~Murray and
            Chris~Olah and
            Mike~Schuster and
            Jonathon~Shlens and
            Benoit~Steiner and
            Ilya~Sutskever and
            Kunal~Talwar and
            Paul~Tucker and
            Vincent~Vanhoucke and
            Vijay~Vasudevan and
            Fernanda~Vi\'{e}gas and
            Oriol~Vinyals and
            Pete~Warden and
            Martin~Wattenberg and
            Martin~Wicke and
            Yuan~Yu and
            Xiaoqiang~Zheng},
  year   = {2015}
}

@misc{tpu,
  title        = {{Cloud Tensor Processing Units (TPUs)}},
  url          = {https://cloud.google.com/tpu/docs/tpus},
  howpublished = {\url{https://cloud.google.com/tpu/docs/tpus}},
  journal      = {Google},
  publisher    = {Google},
  author       = {Google},
  year         = {2021},
  month        = {Nov}
}

@article{Vicuna2021-mw,
  title         = {{Reducing numerical precision preserves classification
                   accuracy in Mondrian Forests}},
  author        = {Vicuna, Marc and Khannouz, Martin and Kiar, Gregory and
                   Chatelain, Yohan and Glatard, Tristan},
  abstract      = {Mondrian Forests are a powerful data stream classification
                   method, but their large memory footprint makes them
                   ill-suited for low-resource platforms such as connected
                   objects. We explored using reduced-precision floating-point
                   representations to lower memory consumption and evaluated
                   its effect on classification performance. We applied the
                   Mondrian Forest implementation provided by OrpailleCC, a C++
                   collection of data stream algorithms, to two canonical
                   datasets in human activity recognition: Recofit and Banos
                   \textbackslashemph\{et al\}. Results show that the precision
                   of floating-point values used by tree nodes can be reduced
                   from 64 bits to 8 bits with no significant difference in F1
                   score. In some cases, reduced precision was shown to improve
                   classification performance, presumably due to its
                   regularization effect. We conclude that numerical precision
                   is a relevant hyperparameter in the Mondrian Forest, and
                   that commonly-used double precision values may not be
                   necessary for optimal performance. Future work will evaluate
                   the generalizability of these findings to other data stream
                   classifiers.},
  month         = jun,
  year          = 2021,
  archiveprefix = {arXiv},
  eprint        = {2106.14340},
  primaryclass  = {cs.LG},
  arxivid       = {2106.14340},
  journal       = {arXiv}
}

@article{Wang2018-oo,
  title         = {{Training Deep Neural Networks with 8-bit floating point
                   numbers}},
  author        = {Wang, Naigang and Choi, Jungwook and Brand, Daniel and Chen,
                   Chia-Yu and Gopalakrishnan, Kailash},
  abstract      = {The state-of-the-art hardware platforms for training Deep
                   Neural Networks (DNNs) are moving from traditional single
                   precision (32-bit) computations towards 16 bits of precision
                   -- in large part due to the high energy efficiency and
                   smaller bit storage associated with using reduced-precision
                   representations. However, unlike inference, training with
                   numbers represented with less than 16 bits has been
                   challenging due to the need to maintain fidelity of the
                   gradient computations during back-propagation. Here we
                   demonstrate, for the first time, the successful training of
                   DNNs using 8-bit floating point numbers while fully
                   maintaining the accuracy on a spectrum of Deep Learning
                   models and datasets. In addition to reducing the data and
                   computation precision to 8 bits, we also successfully reduce
                   the arithmetic precision for additions (used in partial
                   product accumulation and weight updates) from 32 bits to 16
                   bits through the introduction of a number of key ideas
                   including chunk-based accumulation and floating point
                   stochastic rounding. The use of these novel techniques lays
                   the foundation for a new generation of hardware training
                   platforms with the potential for 2-4x improved throughput
                   over today's systems.},
  month         = dec,
  year          = 2018,
  copyright     = {http://arxiv.org/licenses/nonexclusive-distrib/1.0/},
  archiveprefix = {arXiv},
  eprint        = {1812.08011},
  primaryclass  = {cs.LG},
  arxivid       = {1812.08011},
  journal       = {arXiv}
}

@article{Wen2018-to,
  title    = {{Deep Learning Methods to Process fMRI Data and Their Application
              in the Diagnosis of Cognitive Impairment: A Brief Overview and
              Our Opinion}},
  author   = {Wen, Dong and Wei, Zhenhao and Zhou, Yanhong and Li, Guolin and
              Zhang, Xu and Han, Wei},
  journal  = {Front. Neuroinform.},
  volume   = 12,
  pages    = {23},
  month    = apr,
  year     = 2018,
  keywords = {cognitive impairment; convolutional neural network; deep
              learning; deep neural network; fMRI; radial basis function
              network},
  language = {en},
  issn     = {1662-5196},
  pmid     = {29755334},
  doi      = {10.3389/fninf.2018.00023},
  pmc      = {PMC5932168}
}


@article{Wen2018-xm,
  title    = {{Neural Encoding and Decoding with Deep Learning for Dynamic
              Natural Vision}},
  author   = {Wen, Haiguang and Shi, Junxing and Zhang, Yizhen and Lu, Kun-Han
              and Cao, Jiayue and Liu, Zhongming},
  abstract = {Convolutional neural network (CNN) driven by image recognition
              has been shown to be able to explain cortical responses to static
              pictures at ventral-stream areas. Here, we further showed that
              such CNN could reliably predict and decode functional magnetic
              resonance imaging data from humans watching natural movies,
              despite its lack of any mechanism to account for temporal
              dynamics or feedback processing. Using separate data, encoding
              and decoding models were developed and evaluated for describing
              the bi-directional relationships between the CNN and the brain.
              Through the encoding models, the CNN-predicted areas covered not
              only the ventral stream, but also the dorsal stream, albeit to a
              lesser degree; single-voxel response was visualized as the
              specific pixel pattern that drove the response, revealing the
              distinct representation of individual cortical location; cortical
              activation was synthesized from natural images with
              high-throughput to map category representation, contrast, and
              selectivity. Through the decoding models, fMRI signals were
              directly decoded to estimate the feature representations in both
              visual and semantic spaces, for direct visual reconstruction and
              semantic categorization, respectively. These results corroborate,
              generalize, and extend previous findings, and highlight the value
              of using deep learning, as an all-in-one model of the visual
              cortex, to understand and decode natural vision.},
  journal  = {Cereb. Cortex},
  volume   = 28,
  number   = 12,
  pages    = {4136--4160},
  month    = dec,
  year     = 2018,
  language = {en},
  issn     = {1047-3211, 1460-2199},
  pmid     = {29059288},
  doi      = {10.1093/cercor/bhx268},
  pmc      = {PMC6215471}
}

@article{Zhang2019-xv,
  title         = {{QPyTorch: A Low-Precision Arithmetic Simulation Framework}},
  author        = {Zhang, Tianyi and Lin, Zhiqiu and Yang, Guandao and De Sa,
                   Christopher},
  abstract      = {Low-precision training reduces computational cost and
                   produces efficient models. Recent research in developing new
                   low-precision training algorithms often relies on simulation
                   to empirically evaluate the statistical effects of
                   quantization while avoiding the substantial overhead of
                   building specific hardware. To support this empirical
                   research, we introduce QPyTorch, a low-precision arithmetic
                   simulation framework. Built natively in PyTorch, QPyTorch
                   provides a convenient interface that minimizes the efforts
                   needed to reliably convert existing codes to study
                   low-precision training. QPyTorch is general, and supports a
                   variety of combinations of precisions, number formats, and
                   rounding options. Additionally, it leverages an efficient
                   fused-kernel approach to reduce simulator overhead, which
                   enables simulation of large-scale, realistic problems.
                   QPyTorch is publicly available at
                   https://github.com/Tiiiger/QPyTorch.},
  month         = oct,
  year          = 2019,
  archiveprefix = {arXiv},
  eprint        = {1910.04540},
  primaryclass  = {cs.LG},
  arxivid       = {1910.04540},
  journal       = {arXiv}
}


@article{Zou2017-hd,
  title    = {{3D CNN Based Automatic Diagnosis of Attention Deficit
              Hyperactivity Disorder Using Functional and Structural MRI}},
  author   = {Zou, Liang and Zheng, Jiannan and Miao, Chunyan and Mckeown,
              Martin J and Wang, Z Jane},
  abstract = {Attention deficit hyperactivity disorder (ADHD) is one of the
              most common mental health disorders. As a neuro development
              disorder, neuroimaging technologies, such as magnetic resonance
              imaging (MRI), coupled with machine learning algorithms, are
              being increasingly explored as biomarkers in ADHD. Among various
              machine learning methods, deep learning has demonstrated
              excellent performance on many imaging tasks. With the
              availability of publically-available, large neuroimaging data
              sets for training purposes, deep learning-based automatic
              diagnosis of psychiatric disorders can become feasible. In this
              paper, we develop a deep learning-based ADHD classification
              method via 3-D convolutional neural networks (CNNs) applied to
              MRI scans. Since deep neural networks may utilize millions of
              parameters, even the large number of MRI samples in pooled data
              sets is still relatively limited if one is to learn
              discriminative features from the raw data. Instead, here we
              propose to first extract meaningful 3-D low-level features from
              functional MRI (fMRI) and structural MRI (sMRI) data.
              Furthermore, inspired by radiologists' typical approach for
              examining brain images, we design a 3-D CNN model to investigate
              the local spatial patterns of MRI features. Finally, we discover
              that brain functional and structural information are
              complementary, and design a multi-modality CNN architecture to
              combine fMRI and sMRI features. Evaluations on the hold-out
              testing data of the ADHD-200 global competition shows that the
              proposed multi-modality 3-D CNN approach achieves the
              state-of-the-art accuracy of 69.15\% and outperforms reported
              classifiers in the literature, even with fewer training samples.
              We suggest that multi-modality classification will be a promising
              direction to find potential neuroimaging biomarkers of neuro
              development disorders.},
  journal  = {IEEE Access},
  volume   = 5,
  pages    = {23626--23636},
  year     = 2017,
  keywords = {Feature extraction;Three-dimensional
              displays;Testing;Training;Neuroimaging;Biological neural
              networks;Attention deficit hyperactive disorder;3D CNN;magnetic
              resonance imaging;multi-modality analysis},
  issn     = {2169-3536},
  doi      = {10.1109/ACCESS.2017.2762703}
}

@book{Zucker1994-rg,
  title     = {{Reuse of high precision arithmetic hardware to perform multiple
               concurrent low precision calculations}},
  author    = {Zucker, Daniel F and Lee, Ruby B},
  publisher = {Computer Systems Laboratory, Stanford University},
  year      = 1994
}
